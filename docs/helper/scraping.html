<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>helper.scraping API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>helper.scraping</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import random

from pathlib import Path
from miping.models.tweetCollection import TweetCollection
from miping.models.userCollection import UserCollection


class Scraping:
    &#34;&#34;&#34;
    Wrapper class for data collection process (1st step).
    Contains all functions needed for collection. Calls mostly miping
    module functions and allows imports and exports of data via csv.
    Coordinates scraping of data via Twitter API.
    &#34;&#34;&#34;

    def __init__(
        self,
        config,
        twitter,
        maps=None,
    ):
        &#34;&#34;&#34;
        Init function for configuration and APIs.

        Parameters
        ----------
        config : dict, default=None, required
            Configuration object as returned from ConfigLoader class.
        twitter : miping.interfaces.TwitterAPI, default=None, required
            Initialized TwitterAPI object, ready for calls.
        maps : miping.interfaces.MapsAPI, default=None
            Initialized Google Maps API, ready for calls, optional.
        &#34;&#34;&#34;
        self.config = config

        self.twitter = twitter

        self.maps = maps

    def doScrapingByLocation(
        self,
        readFiles=False,
        writeFiles=False,
    ):
        &#34;&#34;&#34;
        Return scraped tweets based on GPS coordinates.

        Allows imports and exports of results via CSV. Expected path is
        &#39;data/01streamed&#39; + countryConf[&#39;name&#39;] + &#39;tweet.csv&#39;.
        Based on coordinates from configuration, Twitter API&#39;s
        stream_tweets_by_location() by location is called. This streams
        tweets in these coordinates for the given time limit (from config).
        Additionally, selection criteria from config regarding
        maximum and minimum follower count, as well as minimum status
        count are passed.

        Parameters
        ----------
        readFiles : boolean, default=False
            If True, CSV files will be read instead of following program
            logic.
        writeFiles : boolean, default=False
            Can only be True, if readFiles is False. If True, will export
            results to CSV files. Allows to read files in the next program
            run.

        Returns
        -------
        returnDictCollection : dict
            Dictionary containing one TweetCollection for each country.
        &#34;&#34;&#34;
        if writeFiles is True and readFiles is True:
            raise Exception(
                &#34;readFiles and writeFiles cannot be True at the same time.&#34;
            )
        # if we scrape data for multiple countries
        # we will gather them in this list
        returnDictCollection = {}

        if readFiles is True:
            print(&#34;\nReading files for scraping by location&#34;)

            # for each country we need to read the file
            for country in self.config[&#39;twitter&#39;][&#39;coordinates&#39;]:
                # getting coordinates for streaming
                countryConf = self.config[&#39;twitter&#39;][&#39;coordinates&#39;][country]

                print(
                    &#34;Loading for country: &#34; +
                    countryConf[&#39;name&#39;]
                )

                # path for saved tweets
                file_directory_string = (
                    &#39;data/01streamed&#39; +
                    countryConf[&#39;name&#39;] +
                    &#39;tweet.csv&#39;
                )
                file_path = Path(file_directory_string)

                scrapedTweets = TweetCollection(
                    additionalAttributes=(
                        self.config[&#34;twitter&#34;][&#34;add_attributes&#34;]
                    )
                )
                scrapedTweets.read_tweet_list_file(
                    full_path=file_path
                )

                # add collection to dict
                returnDictCollection[countryConf[&#39;name&#39;]] = scrapedTweets

            print(&#34;Files successfully loaded&#34;)
        else:
            print(&#34;\nBegin scraping by location&#34;)
            for country in self.config[&#39;twitter&#39;][&#39;coordinates&#39;]:
                # getting coordinates for streaming
                countryConf = self.config[&#39;twitter&#39;][&#39;coordinates&#39;][country]

                location = [
                    countryConf[&#39;southwest&#39;][&#39;lng&#39;],
                    countryConf[&#39;southwest&#39;][&#39;lat&#39;],
                    countryConf[&#39;northeast&#39;][&#39;lng&#39;],
                    countryConf[&#39;northeast&#39;][&#39;lat&#39;]
                ]
                print(
                    &#34;Streaming for country: &#34; +
                    countryConf[&#39;name&#39;]
                )

                scrapeConfig = self.config[&#39;scraping&#39;]
                scrapedTweets = self.twitter.stream_tweets_by_location(
                    location=location,
                    timeLimit=scrapeConfig[&#39;timer&#39;],
                    maxFollowerCount=scrapeConfig[&#39;user_max_followers&#39;],
                    minStatusesCount=scrapeConfig[&#39;users_min_tweet_no&#39;],
                    minFollowerCount=scrapeConfig[&#39;user_min_followers&#39;],
                )

                # only write file if specified
                if writeFiles is True:
                    # path for saving tweets
                    file_directory_string = (
                        &#39;data/01streamed&#39; +
                        countryConf[&#39;name&#39;] +
                        &#39;tweet.csv&#39;
                    )
                    file_path = Path(file_directory_string)

                    scrapedTweets.write_tweet_list_file(
                        full_path=file_path
                    )

                # add collection to dict
                returnDictCollection[countryConf[&#39;name&#39;]] = scrapedTweets
            print(&#34;End scraping by location&#34;)

        return returnDictCollection

    def doFollowerSelection(
        self,
        tweetSampleCol,
        countryName,
        readFiles=False,
        writeFiles=False,
    ):
        &#34;&#34;&#34;
        Read YML file in given path.

        Allows imports and exports of results via CSV. Expected path is
        &#39;data/02streamed&#39; + countryName + &#39;users_location_verified.csv&#39;.
        Based on given tweet collection (retrieved via streaming), user
        profiles will be retrieved. From these profiles users
        will be randomly selected (number is based on config). From these
        selected users, the first 5000 follower user ids will be retrieved.
        First 5000 due to API limitations. Duplicates will be removed.
        Then for all selected follower user ids their full profile
        will be retrieved via Twitter API. Selection criteria for status
        and follower count according to config will be applied.
        In the end lists will be shuffled for more random selection.

        Parameters
        ----------
        tweetSampleCol : TweetCollection, default=None, required
            TweetCollection with users from whom followers should be
            selected.
        countryName : string, default=None, required
            Country name of where the passed users are collected from
            (as specified in config)
        readFiles : boolean, default=False
            If True, CSV files will be read instead of following program
            logic.
        writeFiles : boolean, default=False
            Can only be True, if readFiles is False. If True, will export
            results to CSV files. Allows to read files in the next program
            run.

        Returns
        -------
        locationUsersCol : UserCollection
            Full user objects previously collected via streaming.
            Location for these users is already verified via GPS.
        eligibleFollowersCol : UserCollection
            Eligible users selected from followers of location users.
            Their location has yet to be verified.
        &#34;&#34;&#34;
        if writeFiles is True and readFiles is True:
            raise Exception(
                &#34;readFiles and writeFiles cannot be True at the same time.&#34;
            )

        if readFiles is True:
            print(&#34;\nReading files for Follower Selection&#34;)
            print(
                    &#34;Loading for country: &#34; +
                    countryName
                )

            # path for saved users
            file_directory_string = (
                    &#39;data/02streamed&#39; +
                    countryName
            )
            # users where we know the location
            file_path_loc = Path(
                    file_directory_string +
                    &#39;users_location_verified.csv&#39;
            )
            locationUsersCol = UserCollection()
            locationUsersCol.read_user_list_file(
                full_path=file_path_loc
            )

            file_path_fol = Path(
                    file_directory_string +
                    &#39;users_location_follower.csv&#39;
            )
            # selected followers, we need to verify location
            eligibleFollowersCol = UserCollection()
            eligibleFollowersCol.read_user_list_file(
                full_path=file_path_fol
            )

            print(&#34;Files successfully loaded&#34;)

        else:
            print(
                &#34;\nStart Follower Selection for country &#34; +
                str(countryName)
            )
            scrapeConfig = self.config[&#39;scraping&#39;]
            sampling_follower = scrapeConfig[&#39;sampling_follower&#39;]

            print(
                &#39;Will select followers from &#39; +
                str(sampling_follower) +
                &#39; users retrieved via location scraping. &#39;
            )

            # retrieve user ids from tweets
            userList = tweetSampleCol.get_distinct_user_id_list()

            # get users based on IDs
            # (follower and tweet count already ensured)
            locationUsersCol = self.twitter.getUsersByList(
                userIDList=userList
            )

            # get x random users from list
            # since API limit is limited (to 15 calls / 15 minutes)
            randList = self.getRandomItemsFromList(
                userList,
                sampling_follower
            )

            # get followers of scraped tweets/users
            followers = self.twitter.get_followers_of_user(
                userIDList=randList,
                limit=5000  # 5000 users are returned per API call
            )

            # remove duplicates inside follower list
            followers = list(set(followers))

            # remove duplicates from followers if
            # already in locationUsersCol
            # first get the ids apparent in both lists
            duplicates = set(userList).intersection(followers)
            # second only take the user id (idU) if it&#39;s not in
            # the duplicate list
            followers = [idU for idU in followers if idU not in duplicates]

            # remove duplicates inside follower list, just in case
            followers = list(set(followers))

            # select eligible followers
            # tweet count and follower count will be checked
            eligibleFollowersCol = self.twitter.getUsersByList(
                userIDList=followers,
                maxFollowerCount=scrapeConfig[&#39;user_max_followers&#39;],
                minStatusesCount=scrapeConfig[&#39;users_min_tweet_no&#39;],
                minFollowerCount=scrapeConfig[&#39;user_min_followers&#39;]
            )

            # shuffle lists to have true random selection
            random.shuffle(locationUsersCol.userList)
            random.shuffle(eligibleFollowersCol.userList)

            # only write file if specified
            if writeFiles is True:
                # path for saving users
                file_directory_string = (
                    &#39;data/02streamed&#39; +
                    countryName
                )

                file_path_loc = Path(
                    file_directory_string +
                    &#39;users_location_verified.csv&#39;
                )
                # users where we know the location
                locationUsersCol.write_user_list_file(
                    full_path=file_path_loc
                )

                file_path_fol = Path(
                    file_directory_string +
                    &#39;users_location_follower.csv&#39;
                )
                # selected followers, we need to verify location
                eligibleFollowersCol.write_user_list_file(
                    full_path=file_path_fol
                )

            print(&#34;End Follower Selection&#34;)

        return locationUsersCol, eligibleFollowersCol

    def doUserSelection(
        self,
        country,
        locationUsersCol,
        eligibleFolCol,
        readFiles=False,
        writeFiles=False,
    ):
        &#34;&#34;&#34;
        Returns final selected users and tweets based on verified
        location and language.

        Allows imports and exports of results via CSV. Expected path is
        &#39;data/03verified&#39; + country + &#39;users.csv&#39;.
        In configuration it is defined how big the sample size should
        be and how many users should be selected from which collection.
        For users, whose location has been verified, the language criteria
        have to be checked. If they are met, the user and fitting tweets
        are included in the collection.
        For other users both location and language have to be checked.
        In the end, a combined user collection and combined tweet collection
        is returned, which will be used as input for data preparation.

        Parameters
        ----------
        country : string, default=None, required
            Country name of where the passed users are collected from
            (as specified in config)
        locationUsersCol : UserCollection, default=None, required
            User collection of location verified users (typically
            retrieved via streaming).
        eligibleFolCol : UserCollection, default=None, required
            User collection of users whose location is not verified
            yet. Typically those are retrieved via doFollowerSelection().
        readFiles : boolean, default=False
            If True, CSV files will be read instead of following program
            logic.
        writeFiles : boolean, default=False
            Can only be True, if readFiles is False. If True, will export
            results to CSV files. Allows to read files in the next program
            run.

        Returns
        -------
        verifiedUsers : UserCollection
            Final verified sample of users as collection.
        verifiedTweetCol : TweetCollection
            Final verified sample of tweets as collection (tweets are
            written by users in verifiedUsers).
        &#34;&#34;&#34;
        if writeFiles is True and readFiles is True:
            raise Exception(
                &#34;readFiles and writeFiles cannot be True at the same time.&#34;
            )

        if readFiles is True:
            print(&#34;\nReading files for User Selection&#34;)
            print(
                    &#34;Loading for country: &#34; +
                    country
                )

            # base path for saved
            file_directory_string = (
                    &#39;data/03verified&#39; +
                    country
            )
            # verified and selected users
            file_path_user = Path(
                    file_directory_string +
                    &#39;users.csv&#39;
            )
            verifiedUsers = UserCollection()
            verifiedUsers.read_user_list_file(
                full_path=file_path_user
            )
            # tweets of verified and selected users
            file_path_tweets = Path(
                    file_directory_string +
                    &#39;tweets.csv&#39;
            )
            verifiedTweetCol = TweetCollection(
                additionalAttributes=self.config[&#34;twitter&#34;][&#34;add_attributes&#34;]
            )
            verifiedTweetCol.read_tweet_list_file(
                full_path=file_path_tweets
            )

            print(&#34;Files successfully loaded&#34;)

        else:
            # no loading from file
            sampling_location = (
                self.config[&#39;scraping&#39;][&#39;sampling_location_users&#39;]
            )
            sampling_total = self.config[&#39;scraping&#39;][&#39;total_sample_size&#39;]
            sampling_other = sampling_total - sampling_location

            # verify that user&#39;s language and location is correct
            # this call is for already location verified users
            verifiedUsers, verifiedTweetCol = (
                self.verifyUserLocAndLang(
                    countryID=country,
                    usersCol=locationUsersCol,
                    userLimit=sampling_location,
                    verifyLocation=False
                )
            )
            # this call is for yet to be location verified users
            verifiedUsers2, verifiedTweetCol2 = (
                self.verifyUserLocAndLang(
                    countryID=country,
                    usersCol=eligibleFolCol,
                    userLimit=sampling_other,
                    verifyLocation=self.config[&#39;scraping&#39;][&#39;validateLocation&#39;]
                )
            )

            # join both user and tweet list as our new base of users
            # we add the second results to the first result
            verifiedTweetCol.add_tweet_collection(
                tweetCol=verifiedTweetCol2
            )

            verifiedUsers.userList.extend(verifiedUsers2.userList)

            # only write file if specified
            if writeFiles is True:
                # base path for saved
                file_directory_string = (
                        &#39;data/03verified&#39; +
                        country
                )
                # verified and selected users
                file_path_user = Path(
                        file_directory_string +
                        &#39;users.csv&#39;
                )
                verifiedUsers.write_user_list_file(
                    full_path=file_path_user
                )
                # tweets of verified and selected users
                file_path_tweets = Path(
                        file_directory_string +
                        &#39;tweets.csv&#39;
                )
                verifiedTweetCol.write_tweet_list_file(
                    full_path=file_path_tweets
                )

        return verifiedUsers, verifiedTweetCol

    def verifyUserLocAndLang(
        self,
        countryID,
        usersCol,
        userLimit=10,
        verifyLocation=True,
    ):
        &#34;&#34;&#34;
        Return language and location verified users from collection up
        to given limit.

        A sample should be drawn from the given usersCol. The maximum of
        users to select is given by userLimit. Based on countryID the
        target language and target language criteria are loaded from
        config. `checkUserLanguage` is called and returns eligible tweets,
        that match target language and result if user matches given criteria.
        If not, user is skipped. If yes, location is checked (if flag is True).
        This is done via `checkUserLocation`. If location checks out, user
        is added to verifiedUsers and its tweets to verifiedTweetCol. Counter
        is increased. Process repeated until counter matches limit or all users
        processed.

        Parameters
        ----------
        countryID : string, default=None, required
            Country name of where the passed users are collected from
            (as specified in config)
        usersCol : UserCollection, default=None, required
            User collection from which to draw and verify the sample.
        userLimit : integer, default=10
            Full absolute path for file to be loaded via yaml.safe_load().
        verifyLocation : boolean, default=True
            Full absolute path for file to be loaded via yaml.safe_load().

        Returns
        -------
        verifiedUsers : UserCollection
            Location and language verified users up to userLimit numbers.
        verifiedTweetCol : TweetCollection
            Tweets of verifiedUsers which match the target language.
        &#34;&#34;&#34;
        countryConf = self.config[&#39;twitter&#39;][&#39;coordinates&#39;][countryID]
        countryName = countryConf[&#39;name&#39;]
        targetLanguage = countryConf[&#39;lang&#39;]
        langThreshold = countryConf[&#39;langThreshold&#39;]
        otherLangThreshold = countryConf[&#39;otherLangThreshold&#39;]

        print(
                &#34;\nStart verifying user location and language until &#34; +
                str(userLimit) +
                &#34; users are verified. Target language is &#34; +
                str(targetLanguage) +
                &#34;. Language Threshold is &#34; +
                str(langThreshold) +
                &#34; and other language threshold is &#34; +
                str(otherLangThreshold)
        )

        verifiedCounter = 0
        verifiedUsers = UserCollection()
        verifiedTweetCol = TweetCollection(
            additionalAttributes=self.config[&#34;twitter&#34;][&#34;add_attributes&#34;]
        )

        for num, user in enumerate(usersCol.userList):
            # retrieve user timeline upto max number of tweets
            max_tweets = self.config[&#34;twitter&#34;][&#34;user_max_tweet_no&#34;]
            result, tweetCol = self.checkUserLanguage(
                user,
                targetLanguage=targetLanguage,
                langThreshold=langThreshold,
                otherLangThreshold=otherLangThreshold,
                limit=max_tweets
            )

            if result is True:
                # language of tweets is okay
                # now check if location is US based
                if verifyLocation is True:
                    if user.location == &#39;&#39;:
                        # if user does not give location
                        # result is false
                        locationResult = False
                    else:
                        # checks if user&#39;s location is inside country
                        locationResult = self.checkUserLocation(
                            userLocation=user.location,
                            targetLocation=countryName
                        )

                else:
                    # if we do not verify
                    # it will automatically be true
                    locationResult = True

                if locationResult is True:
                    # for each user append the tweet list
                    # to the verified collection
                    verifiedTweetCol.add_tweet_collection(
                        tweetCol=tweetCol
                    )
                    verifiedUsers.funcAddUser(user)
                    verifiedCounter = verifiedCounter + 1
                    if (verifiedCounter % (userLimit/10)) == 0:
                        # give progress each 10 percent step
                        print(
                            &#34;Current progress: &#34; +
                            str(verifiedCounter) +
                            &#34; verified users.&#34;
                        )

            if verifiedCounter &gt;= userLimit:
                break

        print(
            &#39;Number of inspected users &#39; +
            str(num + 1) +  # 0 based counting
            &#39; to get &#39; +
            str(verifiedCounter) +
            &#39; verified users.&#39;
        )
        if verifiedCounter &lt; userLimit:
            print(&#34;Limit was not reached.&#34;)

        return verifiedUsers, verifiedTweetCol

    def checkUserLanguage(
        self,
        user,
        targetLanguage,
        langThreshold=1,  # 100%
        otherLangThreshold=0,  # 0 %
        limit=3200,
    ):
        &#34;&#34;&#34;
        Check if user timeline matches criteria and return results.

        Based on user ID from user object, tweets are retrieved from
        timeline up to the given limit. Retweets are excluded afterwards.
        Tweets&#39; language tags are analyzed and counted for target language,
        unknown language and forein language. In the end, percentages
        are calcualted and if the meet the thresholds result is True,
        otherwise False. Result and Tweetcollection are returned.

        Parameters
        ----------
        user : miping.models.User, default=None, required
            User object to check.
        targetLanguage : string, default=None, required
            Target language to check user timeline for.
        langThreshold : float, default=1
            Minimum percentage of tweets in timeline that should be tagged
            with target language in order for user to be verified.
        otherLangThreshold : float, default=0
            Maximum percentage of tweets in timeline that have a language
            tag other than the target lanugage and not undefined.
        limit : integer, default=3200
            Maximum number of tweets to select from user. 3200 is
            API limit set by Twitter for free API. This limit includes
            retweets, but those are excluded in the process.

        Returns
        -------
        languageVerified : boolean
            True if user timeline matches language criteria, otherwise false.
        tweetCol : TweetCollection
            Selected tweets from user timeline.
        &#34;&#34;&#34;
        languageVerified = False
        targetTweetCollection = TweetCollection(
            additionalAttributes=self.config[&#34;twitter&#34;][&#34;add_attributes&#34;]
        )
        totalTweets = 0
        tweetsTargetLang = 0
        undefinedTweets = 0
        otherLangTweets = 0

        # get tweets for given user
        tweetCol = self.twitter.funcGetTweetListByUser(
                user.id_str,
                limit=limit
        )
        # total number of tweets
        totalTweets = len(tweetCol.tweetList)

        # loop over all tweets and count language attributes
        for tweet in tweetCol.tweetList:
            if tweet.lang == targetLanguage:
                # correct language
                tweetsTargetLang = tweetsTargetLang + 1
                # add tweet to return collection
                targetTweetCollection.funcAddTweet(tweet)
            elif tweet.lang == &#39;und&#39; or tweet.lang == &#39;&#39;:
                # undefined language
                undefinedTweets = undefinedTweets + 1
            else:
                # other language
                otherLangTweets = otherLangTweets + 1

        # check if there are any tweets
        # possible that a user only posts retweets
        if totalTweets &gt; 0:
            # analyse statistics with thresholds
            # default is False (meaning not verified)
            if (tweetsTargetLang / totalTweets) &gt;= langThreshold:
                # enough target language tweets
                # now check other languages
                if (otherLangTweets / totalTweets) &lt;= otherLangThreshold:
                    # not too much foreign language tweets
                    languageVerified = True
                else:
                    # too many other foreign language tweets
                    languageVerified = False
            else:
                # not enough target language tweets
                languageVerified = False
        else:
            # no tweet -&gt; not verified
            languageVerified = False

        return languageVerified, tweetCol

    def checkUserLocation(
        self,
        userLocation,
        targetLocation,
    ):
        &#34;&#34;&#34;
        Return True if userLocation is a real location and lies inside
        the targetLocation.

        E.g. the city Brunswick, lies withing Brunswick, Lower Saxony State,
        Germany, and Europe. So if the targetLocation is one of the above
        the result will be True.

        Parameters
        ----------
        userLocation : string, default=None, required
            User location as given in Twitter profile.
        targetLocation : string, default=None, required
            Country name as in config file. Has to be country name
            that is valid for Google Maps API.

        Returns
        -------
        locationVerified : boolean
            True if userLocation is within targetLocation, otherwise False.
        &#34;&#34;&#34;
        locationVerified = False

        # call api to get results for user profile location
        result = self.maps.get_address(
            userLocation
        )

        # take first result candidate
        # (google might return multiple)
        if len(result[&#39;candidates&#39;]) &gt; 0:
            address = result[&#39;candidates&#39;][0][&#39;formatted_address&#39;]
            if targetLocation in address:
                locationVerified = True
            else:
                # returned address is not in target country
                locationVerified = False
        else:
            # no results for location
            locationVerified = False

        return locationVerified

    def getRandomItemsFromList(
            self,
            itemList,
            numberOfElements=1,
    ):
        &#34;&#34;&#34;
        Based on itemList returns a random sample.

        Parameters
        ----------
        itemList : list, default=None, required
            List of items to draw sample from.
        numberOfElements : integer, default=1
            Number of samples to draw from list.

        Returns
        -------
        list : list
            Randomly drawn sample.
        &#34;&#34;&#34;
        return random.sample(itemList, numberOfElements)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="helper.scraping.Scraping"><code class="flex name class">
<span>class <span class="ident">Scraping</span></span>
<span>(</span><span>config, twitter, maps=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Wrapper class for data collection process (1st step).
Contains all functions needed for collection. Calls mostly miping
module functions and allows imports and exports of data via csv.
Coordinates scraping of data via Twitter API.</p>
<p>Init function for configuration and APIs.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>config</code></strong> :&ensp;<code>dict</code>, default=<code>None, required</code></dt>
<dd>Configuration object as returned from ConfigLoader class.</dd>
<dt><strong><code>twitter</code></strong> :&ensp;<code>miping.interfaces.TwitterAPI</code>, default=<code>None, required</code></dt>
<dd>Initialized TwitterAPI object, ready for calls.</dd>
<dt><strong><code>maps</code></strong> :&ensp;<code>miping.interfaces.MapsAPI</code>, default=<code>None</code></dt>
<dd>Initialized Google Maps API, ready for calls, optional.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Scraping:
    &#34;&#34;&#34;
    Wrapper class for data collection process (1st step).
    Contains all functions needed for collection. Calls mostly miping
    module functions and allows imports and exports of data via csv.
    Coordinates scraping of data via Twitter API.
    &#34;&#34;&#34;

    def __init__(
        self,
        config,
        twitter,
        maps=None,
    ):
        &#34;&#34;&#34;
        Init function for configuration and APIs.

        Parameters
        ----------
        config : dict, default=None, required
            Configuration object as returned from ConfigLoader class.
        twitter : miping.interfaces.TwitterAPI, default=None, required
            Initialized TwitterAPI object, ready for calls.
        maps : miping.interfaces.MapsAPI, default=None
            Initialized Google Maps API, ready for calls, optional.
        &#34;&#34;&#34;
        self.config = config

        self.twitter = twitter

        self.maps = maps

    def doScrapingByLocation(
        self,
        readFiles=False,
        writeFiles=False,
    ):
        &#34;&#34;&#34;
        Return scraped tweets based on GPS coordinates.

        Allows imports and exports of results via CSV. Expected path is
        &#39;data/01streamed&#39; + countryConf[&#39;name&#39;] + &#39;tweet.csv&#39;.
        Based on coordinates from configuration, Twitter API&#39;s
        stream_tweets_by_location() by location is called. This streams
        tweets in these coordinates for the given time limit (from config).
        Additionally, selection criteria from config regarding
        maximum and minimum follower count, as well as minimum status
        count are passed.

        Parameters
        ----------
        readFiles : boolean, default=False
            If True, CSV files will be read instead of following program
            logic.
        writeFiles : boolean, default=False
            Can only be True, if readFiles is False. If True, will export
            results to CSV files. Allows to read files in the next program
            run.

        Returns
        -------
        returnDictCollection : dict
            Dictionary containing one TweetCollection for each country.
        &#34;&#34;&#34;
        if writeFiles is True and readFiles is True:
            raise Exception(
                &#34;readFiles and writeFiles cannot be True at the same time.&#34;
            )
        # if we scrape data for multiple countries
        # we will gather them in this list
        returnDictCollection = {}

        if readFiles is True:
            print(&#34;\nReading files for scraping by location&#34;)

            # for each country we need to read the file
            for country in self.config[&#39;twitter&#39;][&#39;coordinates&#39;]:
                # getting coordinates for streaming
                countryConf = self.config[&#39;twitter&#39;][&#39;coordinates&#39;][country]

                print(
                    &#34;Loading for country: &#34; +
                    countryConf[&#39;name&#39;]
                )

                # path for saved tweets
                file_directory_string = (
                    &#39;data/01streamed&#39; +
                    countryConf[&#39;name&#39;] +
                    &#39;tweet.csv&#39;
                )
                file_path = Path(file_directory_string)

                scrapedTweets = TweetCollection(
                    additionalAttributes=(
                        self.config[&#34;twitter&#34;][&#34;add_attributes&#34;]
                    )
                )
                scrapedTweets.read_tweet_list_file(
                    full_path=file_path
                )

                # add collection to dict
                returnDictCollection[countryConf[&#39;name&#39;]] = scrapedTweets

            print(&#34;Files successfully loaded&#34;)
        else:
            print(&#34;\nBegin scraping by location&#34;)
            for country in self.config[&#39;twitter&#39;][&#39;coordinates&#39;]:
                # getting coordinates for streaming
                countryConf = self.config[&#39;twitter&#39;][&#39;coordinates&#39;][country]

                location = [
                    countryConf[&#39;southwest&#39;][&#39;lng&#39;],
                    countryConf[&#39;southwest&#39;][&#39;lat&#39;],
                    countryConf[&#39;northeast&#39;][&#39;lng&#39;],
                    countryConf[&#39;northeast&#39;][&#39;lat&#39;]
                ]
                print(
                    &#34;Streaming for country: &#34; +
                    countryConf[&#39;name&#39;]
                )

                scrapeConfig = self.config[&#39;scraping&#39;]
                scrapedTweets = self.twitter.stream_tweets_by_location(
                    location=location,
                    timeLimit=scrapeConfig[&#39;timer&#39;],
                    maxFollowerCount=scrapeConfig[&#39;user_max_followers&#39;],
                    minStatusesCount=scrapeConfig[&#39;users_min_tweet_no&#39;],
                    minFollowerCount=scrapeConfig[&#39;user_min_followers&#39;],
                )

                # only write file if specified
                if writeFiles is True:
                    # path for saving tweets
                    file_directory_string = (
                        &#39;data/01streamed&#39; +
                        countryConf[&#39;name&#39;] +
                        &#39;tweet.csv&#39;
                    )
                    file_path = Path(file_directory_string)

                    scrapedTweets.write_tweet_list_file(
                        full_path=file_path
                    )

                # add collection to dict
                returnDictCollection[countryConf[&#39;name&#39;]] = scrapedTweets
            print(&#34;End scraping by location&#34;)

        return returnDictCollection

    def doFollowerSelection(
        self,
        tweetSampleCol,
        countryName,
        readFiles=False,
        writeFiles=False,
    ):
        &#34;&#34;&#34;
        Read YML file in given path.

        Allows imports and exports of results via CSV. Expected path is
        &#39;data/02streamed&#39; + countryName + &#39;users_location_verified.csv&#39;.
        Based on given tweet collection (retrieved via streaming), user
        profiles will be retrieved. From these profiles users
        will be randomly selected (number is based on config). From these
        selected users, the first 5000 follower user ids will be retrieved.
        First 5000 due to API limitations. Duplicates will be removed.
        Then for all selected follower user ids their full profile
        will be retrieved via Twitter API. Selection criteria for status
        and follower count according to config will be applied.
        In the end lists will be shuffled for more random selection.

        Parameters
        ----------
        tweetSampleCol : TweetCollection, default=None, required
            TweetCollection with users from whom followers should be
            selected.
        countryName : string, default=None, required
            Country name of where the passed users are collected from
            (as specified in config)
        readFiles : boolean, default=False
            If True, CSV files will be read instead of following program
            logic.
        writeFiles : boolean, default=False
            Can only be True, if readFiles is False. If True, will export
            results to CSV files. Allows to read files in the next program
            run.

        Returns
        -------
        locationUsersCol : UserCollection
            Full user objects previously collected via streaming.
            Location for these users is already verified via GPS.
        eligibleFollowersCol : UserCollection
            Eligible users selected from followers of location users.
            Their location has yet to be verified.
        &#34;&#34;&#34;
        if writeFiles is True and readFiles is True:
            raise Exception(
                &#34;readFiles and writeFiles cannot be True at the same time.&#34;
            )

        if readFiles is True:
            print(&#34;\nReading files for Follower Selection&#34;)
            print(
                    &#34;Loading for country: &#34; +
                    countryName
                )

            # path for saved users
            file_directory_string = (
                    &#39;data/02streamed&#39; +
                    countryName
            )
            # users where we know the location
            file_path_loc = Path(
                    file_directory_string +
                    &#39;users_location_verified.csv&#39;
            )
            locationUsersCol = UserCollection()
            locationUsersCol.read_user_list_file(
                full_path=file_path_loc
            )

            file_path_fol = Path(
                    file_directory_string +
                    &#39;users_location_follower.csv&#39;
            )
            # selected followers, we need to verify location
            eligibleFollowersCol = UserCollection()
            eligibleFollowersCol.read_user_list_file(
                full_path=file_path_fol
            )

            print(&#34;Files successfully loaded&#34;)

        else:
            print(
                &#34;\nStart Follower Selection for country &#34; +
                str(countryName)
            )
            scrapeConfig = self.config[&#39;scraping&#39;]
            sampling_follower = scrapeConfig[&#39;sampling_follower&#39;]

            print(
                &#39;Will select followers from &#39; +
                str(sampling_follower) +
                &#39; users retrieved via location scraping. &#39;
            )

            # retrieve user ids from tweets
            userList = tweetSampleCol.get_distinct_user_id_list()

            # get users based on IDs
            # (follower and tweet count already ensured)
            locationUsersCol = self.twitter.getUsersByList(
                userIDList=userList
            )

            # get x random users from list
            # since API limit is limited (to 15 calls / 15 minutes)
            randList = self.getRandomItemsFromList(
                userList,
                sampling_follower
            )

            # get followers of scraped tweets/users
            followers = self.twitter.get_followers_of_user(
                userIDList=randList,
                limit=5000  # 5000 users are returned per API call
            )

            # remove duplicates inside follower list
            followers = list(set(followers))

            # remove duplicates from followers if
            # already in locationUsersCol
            # first get the ids apparent in both lists
            duplicates = set(userList).intersection(followers)
            # second only take the user id (idU) if it&#39;s not in
            # the duplicate list
            followers = [idU for idU in followers if idU not in duplicates]

            # remove duplicates inside follower list, just in case
            followers = list(set(followers))

            # select eligible followers
            # tweet count and follower count will be checked
            eligibleFollowersCol = self.twitter.getUsersByList(
                userIDList=followers,
                maxFollowerCount=scrapeConfig[&#39;user_max_followers&#39;],
                minStatusesCount=scrapeConfig[&#39;users_min_tweet_no&#39;],
                minFollowerCount=scrapeConfig[&#39;user_min_followers&#39;]
            )

            # shuffle lists to have true random selection
            random.shuffle(locationUsersCol.userList)
            random.shuffle(eligibleFollowersCol.userList)

            # only write file if specified
            if writeFiles is True:
                # path for saving users
                file_directory_string = (
                    &#39;data/02streamed&#39; +
                    countryName
                )

                file_path_loc = Path(
                    file_directory_string +
                    &#39;users_location_verified.csv&#39;
                )
                # users where we know the location
                locationUsersCol.write_user_list_file(
                    full_path=file_path_loc
                )

                file_path_fol = Path(
                    file_directory_string +
                    &#39;users_location_follower.csv&#39;
                )
                # selected followers, we need to verify location
                eligibleFollowersCol.write_user_list_file(
                    full_path=file_path_fol
                )

            print(&#34;End Follower Selection&#34;)

        return locationUsersCol, eligibleFollowersCol

    def doUserSelection(
        self,
        country,
        locationUsersCol,
        eligibleFolCol,
        readFiles=False,
        writeFiles=False,
    ):
        &#34;&#34;&#34;
        Returns final selected users and tweets based on verified
        location and language.

        Allows imports and exports of results via CSV. Expected path is
        &#39;data/03verified&#39; + country + &#39;users.csv&#39;.
        In configuration it is defined how big the sample size should
        be and how many users should be selected from which collection.
        For users, whose location has been verified, the language criteria
        have to be checked. If they are met, the user and fitting tweets
        are included in the collection.
        For other users both location and language have to be checked.
        In the end, a combined user collection and combined tweet collection
        is returned, which will be used as input for data preparation.

        Parameters
        ----------
        country : string, default=None, required
            Country name of where the passed users are collected from
            (as specified in config)
        locationUsersCol : UserCollection, default=None, required
            User collection of location verified users (typically
            retrieved via streaming).
        eligibleFolCol : UserCollection, default=None, required
            User collection of users whose location is not verified
            yet. Typically those are retrieved via doFollowerSelection().
        readFiles : boolean, default=False
            If True, CSV files will be read instead of following program
            logic.
        writeFiles : boolean, default=False
            Can only be True, if readFiles is False. If True, will export
            results to CSV files. Allows to read files in the next program
            run.

        Returns
        -------
        verifiedUsers : UserCollection
            Final verified sample of users as collection.
        verifiedTweetCol : TweetCollection
            Final verified sample of tweets as collection (tweets are
            written by users in verifiedUsers).
        &#34;&#34;&#34;
        if writeFiles is True and readFiles is True:
            raise Exception(
                &#34;readFiles and writeFiles cannot be True at the same time.&#34;
            )

        if readFiles is True:
            print(&#34;\nReading files for User Selection&#34;)
            print(
                    &#34;Loading for country: &#34; +
                    country
                )

            # base path for saved
            file_directory_string = (
                    &#39;data/03verified&#39; +
                    country
            )
            # verified and selected users
            file_path_user = Path(
                    file_directory_string +
                    &#39;users.csv&#39;
            )
            verifiedUsers = UserCollection()
            verifiedUsers.read_user_list_file(
                full_path=file_path_user
            )
            # tweets of verified and selected users
            file_path_tweets = Path(
                    file_directory_string +
                    &#39;tweets.csv&#39;
            )
            verifiedTweetCol = TweetCollection(
                additionalAttributes=self.config[&#34;twitter&#34;][&#34;add_attributes&#34;]
            )
            verifiedTweetCol.read_tweet_list_file(
                full_path=file_path_tweets
            )

            print(&#34;Files successfully loaded&#34;)

        else:
            # no loading from file
            sampling_location = (
                self.config[&#39;scraping&#39;][&#39;sampling_location_users&#39;]
            )
            sampling_total = self.config[&#39;scraping&#39;][&#39;total_sample_size&#39;]
            sampling_other = sampling_total - sampling_location

            # verify that user&#39;s language and location is correct
            # this call is for already location verified users
            verifiedUsers, verifiedTweetCol = (
                self.verifyUserLocAndLang(
                    countryID=country,
                    usersCol=locationUsersCol,
                    userLimit=sampling_location,
                    verifyLocation=False
                )
            )
            # this call is for yet to be location verified users
            verifiedUsers2, verifiedTweetCol2 = (
                self.verifyUserLocAndLang(
                    countryID=country,
                    usersCol=eligibleFolCol,
                    userLimit=sampling_other,
                    verifyLocation=self.config[&#39;scraping&#39;][&#39;validateLocation&#39;]
                )
            )

            # join both user and tweet list as our new base of users
            # we add the second results to the first result
            verifiedTweetCol.add_tweet_collection(
                tweetCol=verifiedTweetCol2
            )

            verifiedUsers.userList.extend(verifiedUsers2.userList)

            # only write file if specified
            if writeFiles is True:
                # base path for saved
                file_directory_string = (
                        &#39;data/03verified&#39; +
                        country
                )
                # verified and selected users
                file_path_user = Path(
                        file_directory_string +
                        &#39;users.csv&#39;
                )
                verifiedUsers.write_user_list_file(
                    full_path=file_path_user
                )
                # tweets of verified and selected users
                file_path_tweets = Path(
                        file_directory_string +
                        &#39;tweets.csv&#39;
                )
                verifiedTweetCol.write_tweet_list_file(
                    full_path=file_path_tweets
                )

        return verifiedUsers, verifiedTweetCol

    def verifyUserLocAndLang(
        self,
        countryID,
        usersCol,
        userLimit=10,
        verifyLocation=True,
    ):
        &#34;&#34;&#34;
        Return language and location verified users from collection up
        to given limit.

        A sample should be drawn from the given usersCol. The maximum of
        users to select is given by userLimit. Based on countryID the
        target language and target language criteria are loaded from
        config. `checkUserLanguage` is called and returns eligible tweets,
        that match target language and result if user matches given criteria.
        If not, user is skipped. If yes, location is checked (if flag is True).
        This is done via `checkUserLocation`. If location checks out, user
        is added to verifiedUsers and its tweets to verifiedTweetCol. Counter
        is increased. Process repeated until counter matches limit or all users
        processed.

        Parameters
        ----------
        countryID : string, default=None, required
            Country name of where the passed users are collected from
            (as specified in config)
        usersCol : UserCollection, default=None, required
            User collection from which to draw and verify the sample.
        userLimit : integer, default=10
            Full absolute path for file to be loaded via yaml.safe_load().
        verifyLocation : boolean, default=True
            Full absolute path for file to be loaded via yaml.safe_load().

        Returns
        -------
        verifiedUsers : UserCollection
            Location and language verified users up to userLimit numbers.
        verifiedTweetCol : TweetCollection
            Tweets of verifiedUsers which match the target language.
        &#34;&#34;&#34;
        countryConf = self.config[&#39;twitter&#39;][&#39;coordinates&#39;][countryID]
        countryName = countryConf[&#39;name&#39;]
        targetLanguage = countryConf[&#39;lang&#39;]
        langThreshold = countryConf[&#39;langThreshold&#39;]
        otherLangThreshold = countryConf[&#39;otherLangThreshold&#39;]

        print(
                &#34;\nStart verifying user location and language until &#34; +
                str(userLimit) +
                &#34; users are verified. Target language is &#34; +
                str(targetLanguage) +
                &#34;. Language Threshold is &#34; +
                str(langThreshold) +
                &#34; and other language threshold is &#34; +
                str(otherLangThreshold)
        )

        verifiedCounter = 0
        verifiedUsers = UserCollection()
        verifiedTweetCol = TweetCollection(
            additionalAttributes=self.config[&#34;twitter&#34;][&#34;add_attributes&#34;]
        )

        for num, user in enumerate(usersCol.userList):
            # retrieve user timeline upto max number of tweets
            max_tweets = self.config[&#34;twitter&#34;][&#34;user_max_tweet_no&#34;]
            result, tweetCol = self.checkUserLanguage(
                user,
                targetLanguage=targetLanguage,
                langThreshold=langThreshold,
                otherLangThreshold=otherLangThreshold,
                limit=max_tweets
            )

            if result is True:
                # language of tweets is okay
                # now check if location is US based
                if verifyLocation is True:
                    if user.location == &#39;&#39;:
                        # if user does not give location
                        # result is false
                        locationResult = False
                    else:
                        # checks if user&#39;s location is inside country
                        locationResult = self.checkUserLocation(
                            userLocation=user.location,
                            targetLocation=countryName
                        )

                else:
                    # if we do not verify
                    # it will automatically be true
                    locationResult = True

                if locationResult is True:
                    # for each user append the tweet list
                    # to the verified collection
                    verifiedTweetCol.add_tweet_collection(
                        tweetCol=tweetCol
                    )
                    verifiedUsers.funcAddUser(user)
                    verifiedCounter = verifiedCounter + 1
                    if (verifiedCounter % (userLimit/10)) == 0:
                        # give progress each 10 percent step
                        print(
                            &#34;Current progress: &#34; +
                            str(verifiedCounter) +
                            &#34; verified users.&#34;
                        )

            if verifiedCounter &gt;= userLimit:
                break

        print(
            &#39;Number of inspected users &#39; +
            str(num + 1) +  # 0 based counting
            &#39; to get &#39; +
            str(verifiedCounter) +
            &#39; verified users.&#39;
        )
        if verifiedCounter &lt; userLimit:
            print(&#34;Limit was not reached.&#34;)

        return verifiedUsers, verifiedTweetCol

    def checkUserLanguage(
        self,
        user,
        targetLanguage,
        langThreshold=1,  # 100%
        otherLangThreshold=0,  # 0 %
        limit=3200,
    ):
        &#34;&#34;&#34;
        Check if user timeline matches criteria and return results.

        Based on user ID from user object, tweets are retrieved from
        timeline up to the given limit. Retweets are excluded afterwards.
        Tweets&#39; language tags are analyzed and counted for target language,
        unknown language and forein language. In the end, percentages
        are calcualted and if the meet the thresholds result is True,
        otherwise False. Result and Tweetcollection are returned.

        Parameters
        ----------
        user : miping.models.User, default=None, required
            User object to check.
        targetLanguage : string, default=None, required
            Target language to check user timeline for.
        langThreshold : float, default=1
            Minimum percentage of tweets in timeline that should be tagged
            with target language in order for user to be verified.
        otherLangThreshold : float, default=0
            Maximum percentage of tweets in timeline that have a language
            tag other than the target lanugage and not undefined.
        limit : integer, default=3200
            Maximum number of tweets to select from user. 3200 is
            API limit set by Twitter for free API. This limit includes
            retweets, but those are excluded in the process.

        Returns
        -------
        languageVerified : boolean
            True if user timeline matches language criteria, otherwise false.
        tweetCol : TweetCollection
            Selected tweets from user timeline.
        &#34;&#34;&#34;
        languageVerified = False
        targetTweetCollection = TweetCollection(
            additionalAttributes=self.config[&#34;twitter&#34;][&#34;add_attributes&#34;]
        )
        totalTweets = 0
        tweetsTargetLang = 0
        undefinedTweets = 0
        otherLangTweets = 0

        # get tweets for given user
        tweetCol = self.twitter.funcGetTweetListByUser(
                user.id_str,
                limit=limit
        )
        # total number of tweets
        totalTweets = len(tweetCol.tweetList)

        # loop over all tweets and count language attributes
        for tweet in tweetCol.tweetList:
            if tweet.lang == targetLanguage:
                # correct language
                tweetsTargetLang = tweetsTargetLang + 1
                # add tweet to return collection
                targetTweetCollection.funcAddTweet(tweet)
            elif tweet.lang == &#39;und&#39; or tweet.lang == &#39;&#39;:
                # undefined language
                undefinedTweets = undefinedTweets + 1
            else:
                # other language
                otherLangTweets = otherLangTweets + 1

        # check if there are any tweets
        # possible that a user only posts retweets
        if totalTweets &gt; 0:
            # analyse statistics with thresholds
            # default is False (meaning not verified)
            if (tweetsTargetLang / totalTweets) &gt;= langThreshold:
                # enough target language tweets
                # now check other languages
                if (otherLangTweets / totalTweets) &lt;= otherLangThreshold:
                    # not too much foreign language tweets
                    languageVerified = True
                else:
                    # too many other foreign language tweets
                    languageVerified = False
            else:
                # not enough target language tweets
                languageVerified = False
        else:
            # no tweet -&gt; not verified
            languageVerified = False

        return languageVerified, tweetCol

    def checkUserLocation(
        self,
        userLocation,
        targetLocation,
    ):
        &#34;&#34;&#34;
        Return True if userLocation is a real location and lies inside
        the targetLocation.

        E.g. the city Brunswick, lies withing Brunswick, Lower Saxony State,
        Germany, and Europe. So if the targetLocation is one of the above
        the result will be True.

        Parameters
        ----------
        userLocation : string, default=None, required
            User location as given in Twitter profile.
        targetLocation : string, default=None, required
            Country name as in config file. Has to be country name
            that is valid for Google Maps API.

        Returns
        -------
        locationVerified : boolean
            True if userLocation is within targetLocation, otherwise False.
        &#34;&#34;&#34;
        locationVerified = False

        # call api to get results for user profile location
        result = self.maps.get_address(
            userLocation
        )

        # take first result candidate
        # (google might return multiple)
        if len(result[&#39;candidates&#39;]) &gt; 0:
            address = result[&#39;candidates&#39;][0][&#39;formatted_address&#39;]
            if targetLocation in address:
                locationVerified = True
            else:
                # returned address is not in target country
                locationVerified = False
        else:
            # no results for location
            locationVerified = False

        return locationVerified

    def getRandomItemsFromList(
            self,
            itemList,
            numberOfElements=1,
    ):
        &#34;&#34;&#34;
        Based on itemList returns a random sample.

        Parameters
        ----------
        itemList : list, default=None, required
            List of items to draw sample from.
        numberOfElements : integer, default=1
            Number of samples to draw from list.

        Returns
        -------
        list : list
            Randomly drawn sample.
        &#34;&#34;&#34;
        return random.sample(itemList, numberOfElements)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="helper.scraping.Scraping.checkUserLanguage"><code class="name flex">
<span>def <span class="ident">checkUserLanguage</span></span>(<span>self, user, targetLanguage, langThreshold=1, otherLangThreshold=0, limit=3200)</span>
</code></dt>
<dd>
<div class="desc"><p>Check if user timeline matches criteria and return results.</p>
<p>Based on user ID from user object, tweets are retrieved from
timeline up to the given limit. Retweets are excluded afterwards.
Tweets' language tags are analyzed and counted for target language,
unknown language and forein language. In the end, percentages
are calcualted and if the meet the thresholds result is True,
otherwise False. Result and Tweetcollection are returned.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>user</code></strong> :&ensp;<code>miping.models.User</code>, default=<code>None, required</code></dt>
<dd>User object to check.</dd>
<dt><strong><code>targetLanguage</code></strong> :&ensp;<code>string</code>, default=<code>None, required</code></dt>
<dd>Target language to check user timeline for.</dd>
<dt><strong><code>langThreshold</code></strong> :&ensp;<code>float</code>, default=<code>1</code></dt>
<dd>Minimum percentage of tweets in timeline that should be tagged
with target language in order for user to be verified.</dd>
<dt><strong><code>otherLangThreshold</code></strong> :&ensp;<code>float</code>, default=<code>0</code></dt>
<dd>Maximum percentage of tweets in timeline that have a language
tag other than the target lanugage and not undefined.</dd>
<dt><strong><code>limit</code></strong> :&ensp;<code>integer</code>, default=<code>3200</code></dt>
<dd>Maximum number of tweets to select from user. 3200 is
API limit set by Twitter for free API. This limit includes
retweets, but those are excluded in the process.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>languageVerified</code></strong> :&ensp;<code>boolean</code></dt>
<dd>True if user timeline matches language criteria, otherwise false.</dd>
<dt><strong><code>tweetCol</code></strong> :&ensp;<code>TweetCollection</code></dt>
<dd>Selected tweets from user timeline.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def checkUserLanguage(
    self,
    user,
    targetLanguage,
    langThreshold=1,  # 100%
    otherLangThreshold=0,  # 0 %
    limit=3200,
):
    &#34;&#34;&#34;
    Check if user timeline matches criteria and return results.

    Based on user ID from user object, tweets are retrieved from
    timeline up to the given limit. Retweets are excluded afterwards.
    Tweets&#39; language tags are analyzed and counted for target language,
    unknown language and forein language. In the end, percentages
    are calcualted and if the meet the thresholds result is True,
    otherwise False. Result and Tweetcollection are returned.

    Parameters
    ----------
    user : miping.models.User, default=None, required
        User object to check.
    targetLanguage : string, default=None, required
        Target language to check user timeline for.
    langThreshold : float, default=1
        Minimum percentage of tweets in timeline that should be tagged
        with target language in order for user to be verified.
    otherLangThreshold : float, default=0
        Maximum percentage of tweets in timeline that have a language
        tag other than the target lanugage and not undefined.
    limit : integer, default=3200
        Maximum number of tweets to select from user. 3200 is
        API limit set by Twitter for free API. This limit includes
        retweets, but those are excluded in the process.

    Returns
    -------
    languageVerified : boolean
        True if user timeline matches language criteria, otherwise false.
    tweetCol : TweetCollection
        Selected tweets from user timeline.
    &#34;&#34;&#34;
    languageVerified = False
    targetTweetCollection = TweetCollection(
        additionalAttributes=self.config[&#34;twitter&#34;][&#34;add_attributes&#34;]
    )
    totalTweets = 0
    tweetsTargetLang = 0
    undefinedTweets = 0
    otherLangTweets = 0

    # get tweets for given user
    tweetCol = self.twitter.funcGetTweetListByUser(
            user.id_str,
            limit=limit
    )
    # total number of tweets
    totalTweets = len(tweetCol.tweetList)

    # loop over all tweets and count language attributes
    for tweet in tweetCol.tweetList:
        if tweet.lang == targetLanguage:
            # correct language
            tweetsTargetLang = tweetsTargetLang + 1
            # add tweet to return collection
            targetTweetCollection.funcAddTweet(tweet)
        elif tweet.lang == &#39;und&#39; or tweet.lang == &#39;&#39;:
            # undefined language
            undefinedTweets = undefinedTweets + 1
        else:
            # other language
            otherLangTweets = otherLangTweets + 1

    # check if there are any tweets
    # possible that a user only posts retweets
    if totalTweets &gt; 0:
        # analyse statistics with thresholds
        # default is False (meaning not verified)
        if (tweetsTargetLang / totalTweets) &gt;= langThreshold:
            # enough target language tweets
            # now check other languages
            if (otherLangTweets / totalTweets) &lt;= otherLangThreshold:
                # not too much foreign language tweets
                languageVerified = True
            else:
                # too many other foreign language tweets
                languageVerified = False
        else:
            # not enough target language tweets
            languageVerified = False
    else:
        # no tweet -&gt; not verified
        languageVerified = False

    return languageVerified, tweetCol</code></pre>
</details>
</dd>
<dt id="helper.scraping.Scraping.checkUserLocation"><code class="name flex">
<span>def <span class="ident">checkUserLocation</span></span>(<span>self, userLocation, targetLocation)</span>
</code></dt>
<dd>
<div class="desc"><p>Return True if userLocation is a real location and lies inside
the targetLocation.</p>
<p>E.g. the city Brunswick, lies withing Brunswick, Lower Saxony State,
Germany, and Europe. So if the targetLocation is one of the above
the result will be True.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>userLocation</code></strong> :&ensp;<code>string</code>, default=<code>None, required</code></dt>
<dd>User location as given in Twitter profile.</dd>
<dt><strong><code>targetLocation</code></strong> :&ensp;<code>string</code>, default=<code>None, required</code></dt>
<dd>Country name as in config file. Has to be country name
that is valid for Google Maps API.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>locationVerified</code></strong> :&ensp;<code>boolean</code></dt>
<dd>True if userLocation is within targetLocation, otherwise False.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def checkUserLocation(
    self,
    userLocation,
    targetLocation,
):
    &#34;&#34;&#34;
    Return True if userLocation is a real location and lies inside
    the targetLocation.

    E.g. the city Brunswick, lies withing Brunswick, Lower Saxony State,
    Germany, and Europe. So if the targetLocation is one of the above
    the result will be True.

    Parameters
    ----------
    userLocation : string, default=None, required
        User location as given in Twitter profile.
    targetLocation : string, default=None, required
        Country name as in config file. Has to be country name
        that is valid for Google Maps API.

    Returns
    -------
    locationVerified : boolean
        True if userLocation is within targetLocation, otherwise False.
    &#34;&#34;&#34;
    locationVerified = False

    # call api to get results for user profile location
    result = self.maps.get_address(
        userLocation
    )

    # take first result candidate
    # (google might return multiple)
    if len(result[&#39;candidates&#39;]) &gt; 0:
        address = result[&#39;candidates&#39;][0][&#39;formatted_address&#39;]
        if targetLocation in address:
            locationVerified = True
        else:
            # returned address is not in target country
            locationVerified = False
    else:
        # no results for location
        locationVerified = False

    return locationVerified</code></pre>
</details>
</dd>
<dt id="helper.scraping.Scraping.doFollowerSelection"><code class="name flex">
<span>def <span class="ident">doFollowerSelection</span></span>(<span>self, tweetSampleCol, countryName, readFiles=False, writeFiles=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Read YML file in given path.</p>
<p>Allows imports and exports of results via CSV. Expected path is
'data/02streamed' + countryName + 'users_location_verified.csv'.
Based on given tweet collection (retrieved via streaming), user
profiles will be retrieved. From these profiles users
will be randomly selected (number is based on config). From these
selected users, the first 5000 follower user ids will be retrieved.
First 5000 due to API limitations. Duplicates will be removed.
Then for all selected follower user ids their full profile
will be retrieved via Twitter API. Selection criteria for status
and follower count according to config will be applied.
In the end lists will be shuffled for more random selection.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tweetSampleCol</code></strong> :&ensp;<code>TweetCollection</code>, default=<code>None, required</code></dt>
<dd>TweetCollection with users from whom followers should be
selected.</dd>
<dt><strong><code>countryName</code></strong> :&ensp;<code>string</code>, default=<code>None, required</code></dt>
<dd>Country name of where the passed users are collected from
(as specified in config)</dd>
<dt><strong><code>readFiles</code></strong> :&ensp;<code>boolean</code>, default=<code>False</code></dt>
<dd>If True, CSV files will be read instead of following program
logic.</dd>
<dt><strong><code>writeFiles</code></strong> :&ensp;<code>boolean</code>, default=<code>False</code></dt>
<dd>Can only be True, if readFiles is False. If True, will export
results to CSV files. Allows to read files in the next program
run.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>locationUsersCol</code></strong> :&ensp;<code>UserCollection</code></dt>
<dd>Full user objects previously collected via streaming.
Location for these users is already verified via GPS.</dd>
<dt><strong><code>eligibleFollowersCol</code></strong> :&ensp;<code>UserCollection</code></dt>
<dd>Eligible users selected from followers of location users.
Their location has yet to be verified.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def doFollowerSelection(
    self,
    tweetSampleCol,
    countryName,
    readFiles=False,
    writeFiles=False,
):
    &#34;&#34;&#34;
    Read YML file in given path.

    Allows imports and exports of results via CSV. Expected path is
    &#39;data/02streamed&#39; + countryName + &#39;users_location_verified.csv&#39;.
    Based on given tweet collection (retrieved via streaming), user
    profiles will be retrieved. From these profiles users
    will be randomly selected (number is based on config). From these
    selected users, the first 5000 follower user ids will be retrieved.
    First 5000 due to API limitations. Duplicates will be removed.
    Then for all selected follower user ids their full profile
    will be retrieved via Twitter API. Selection criteria for status
    and follower count according to config will be applied.
    In the end lists will be shuffled for more random selection.

    Parameters
    ----------
    tweetSampleCol : TweetCollection, default=None, required
        TweetCollection with users from whom followers should be
        selected.
    countryName : string, default=None, required
        Country name of where the passed users are collected from
        (as specified in config)
    readFiles : boolean, default=False
        If True, CSV files will be read instead of following program
        logic.
    writeFiles : boolean, default=False
        Can only be True, if readFiles is False. If True, will export
        results to CSV files. Allows to read files in the next program
        run.

    Returns
    -------
    locationUsersCol : UserCollection
        Full user objects previously collected via streaming.
        Location for these users is already verified via GPS.
    eligibleFollowersCol : UserCollection
        Eligible users selected from followers of location users.
        Their location has yet to be verified.
    &#34;&#34;&#34;
    if writeFiles is True and readFiles is True:
        raise Exception(
            &#34;readFiles and writeFiles cannot be True at the same time.&#34;
        )

    if readFiles is True:
        print(&#34;\nReading files for Follower Selection&#34;)
        print(
                &#34;Loading for country: &#34; +
                countryName
            )

        # path for saved users
        file_directory_string = (
                &#39;data/02streamed&#39; +
                countryName
        )
        # users where we know the location
        file_path_loc = Path(
                file_directory_string +
                &#39;users_location_verified.csv&#39;
        )
        locationUsersCol = UserCollection()
        locationUsersCol.read_user_list_file(
            full_path=file_path_loc
        )

        file_path_fol = Path(
                file_directory_string +
                &#39;users_location_follower.csv&#39;
        )
        # selected followers, we need to verify location
        eligibleFollowersCol = UserCollection()
        eligibleFollowersCol.read_user_list_file(
            full_path=file_path_fol
        )

        print(&#34;Files successfully loaded&#34;)

    else:
        print(
            &#34;\nStart Follower Selection for country &#34; +
            str(countryName)
        )
        scrapeConfig = self.config[&#39;scraping&#39;]
        sampling_follower = scrapeConfig[&#39;sampling_follower&#39;]

        print(
            &#39;Will select followers from &#39; +
            str(sampling_follower) +
            &#39; users retrieved via location scraping. &#39;
        )

        # retrieve user ids from tweets
        userList = tweetSampleCol.get_distinct_user_id_list()

        # get users based on IDs
        # (follower and tweet count already ensured)
        locationUsersCol = self.twitter.getUsersByList(
            userIDList=userList
        )

        # get x random users from list
        # since API limit is limited (to 15 calls / 15 minutes)
        randList = self.getRandomItemsFromList(
            userList,
            sampling_follower
        )

        # get followers of scraped tweets/users
        followers = self.twitter.get_followers_of_user(
            userIDList=randList,
            limit=5000  # 5000 users are returned per API call
        )

        # remove duplicates inside follower list
        followers = list(set(followers))

        # remove duplicates from followers if
        # already in locationUsersCol
        # first get the ids apparent in both lists
        duplicates = set(userList).intersection(followers)
        # second only take the user id (idU) if it&#39;s not in
        # the duplicate list
        followers = [idU for idU in followers if idU not in duplicates]

        # remove duplicates inside follower list, just in case
        followers = list(set(followers))

        # select eligible followers
        # tweet count and follower count will be checked
        eligibleFollowersCol = self.twitter.getUsersByList(
            userIDList=followers,
            maxFollowerCount=scrapeConfig[&#39;user_max_followers&#39;],
            minStatusesCount=scrapeConfig[&#39;users_min_tweet_no&#39;],
            minFollowerCount=scrapeConfig[&#39;user_min_followers&#39;]
        )

        # shuffle lists to have true random selection
        random.shuffle(locationUsersCol.userList)
        random.shuffle(eligibleFollowersCol.userList)

        # only write file if specified
        if writeFiles is True:
            # path for saving users
            file_directory_string = (
                &#39;data/02streamed&#39; +
                countryName
            )

            file_path_loc = Path(
                file_directory_string +
                &#39;users_location_verified.csv&#39;
            )
            # users where we know the location
            locationUsersCol.write_user_list_file(
                full_path=file_path_loc
            )

            file_path_fol = Path(
                file_directory_string +
                &#39;users_location_follower.csv&#39;
            )
            # selected followers, we need to verify location
            eligibleFollowersCol.write_user_list_file(
                full_path=file_path_fol
            )

        print(&#34;End Follower Selection&#34;)

    return locationUsersCol, eligibleFollowersCol</code></pre>
</details>
</dd>
<dt id="helper.scraping.Scraping.doScrapingByLocation"><code class="name flex">
<span>def <span class="ident">doScrapingByLocation</span></span>(<span>self, readFiles=False, writeFiles=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Return scraped tweets based on GPS coordinates.</p>
<p>Allows imports and exports of results via CSV. Expected path is
'data/01streamed' + countryConf['name'] + 'tweet.csv'.
Based on coordinates from configuration, Twitter API's
stream_tweets_by_location() by location is called. This streams
tweets in these coordinates for the given time limit (from config).
Additionally, selection criteria from config regarding
maximum and minimum follower count, as well as minimum status
count are passed.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>readFiles</code></strong> :&ensp;<code>boolean</code>, default=<code>False</code></dt>
<dd>If True, CSV files will be read instead of following program
logic.</dd>
<dt><strong><code>writeFiles</code></strong> :&ensp;<code>boolean</code>, default=<code>False</code></dt>
<dd>Can only be True, if readFiles is False. If True, will export
results to CSV files. Allows to read files in the next program
run.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>returnDictCollection</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary containing one TweetCollection for each country.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def doScrapingByLocation(
    self,
    readFiles=False,
    writeFiles=False,
):
    &#34;&#34;&#34;
    Return scraped tweets based on GPS coordinates.

    Allows imports and exports of results via CSV. Expected path is
    &#39;data/01streamed&#39; + countryConf[&#39;name&#39;] + &#39;tweet.csv&#39;.
    Based on coordinates from configuration, Twitter API&#39;s
    stream_tweets_by_location() by location is called. This streams
    tweets in these coordinates for the given time limit (from config).
    Additionally, selection criteria from config regarding
    maximum and minimum follower count, as well as minimum status
    count are passed.

    Parameters
    ----------
    readFiles : boolean, default=False
        If True, CSV files will be read instead of following program
        logic.
    writeFiles : boolean, default=False
        Can only be True, if readFiles is False. If True, will export
        results to CSV files. Allows to read files in the next program
        run.

    Returns
    -------
    returnDictCollection : dict
        Dictionary containing one TweetCollection for each country.
    &#34;&#34;&#34;
    if writeFiles is True and readFiles is True:
        raise Exception(
            &#34;readFiles and writeFiles cannot be True at the same time.&#34;
        )
    # if we scrape data for multiple countries
    # we will gather them in this list
    returnDictCollection = {}

    if readFiles is True:
        print(&#34;\nReading files for scraping by location&#34;)

        # for each country we need to read the file
        for country in self.config[&#39;twitter&#39;][&#39;coordinates&#39;]:
            # getting coordinates for streaming
            countryConf = self.config[&#39;twitter&#39;][&#39;coordinates&#39;][country]

            print(
                &#34;Loading for country: &#34; +
                countryConf[&#39;name&#39;]
            )

            # path for saved tweets
            file_directory_string = (
                &#39;data/01streamed&#39; +
                countryConf[&#39;name&#39;] +
                &#39;tweet.csv&#39;
            )
            file_path = Path(file_directory_string)

            scrapedTweets = TweetCollection(
                additionalAttributes=(
                    self.config[&#34;twitter&#34;][&#34;add_attributes&#34;]
                )
            )
            scrapedTweets.read_tweet_list_file(
                full_path=file_path
            )

            # add collection to dict
            returnDictCollection[countryConf[&#39;name&#39;]] = scrapedTweets

        print(&#34;Files successfully loaded&#34;)
    else:
        print(&#34;\nBegin scraping by location&#34;)
        for country in self.config[&#39;twitter&#39;][&#39;coordinates&#39;]:
            # getting coordinates for streaming
            countryConf = self.config[&#39;twitter&#39;][&#39;coordinates&#39;][country]

            location = [
                countryConf[&#39;southwest&#39;][&#39;lng&#39;],
                countryConf[&#39;southwest&#39;][&#39;lat&#39;],
                countryConf[&#39;northeast&#39;][&#39;lng&#39;],
                countryConf[&#39;northeast&#39;][&#39;lat&#39;]
            ]
            print(
                &#34;Streaming for country: &#34; +
                countryConf[&#39;name&#39;]
            )

            scrapeConfig = self.config[&#39;scraping&#39;]
            scrapedTweets = self.twitter.stream_tweets_by_location(
                location=location,
                timeLimit=scrapeConfig[&#39;timer&#39;],
                maxFollowerCount=scrapeConfig[&#39;user_max_followers&#39;],
                minStatusesCount=scrapeConfig[&#39;users_min_tweet_no&#39;],
                minFollowerCount=scrapeConfig[&#39;user_min_followers&#39;],
            )

            # only write file if specified
            if writeFiles is True:
                # path for saving tweets
                file_directory_string = (
                    &#39;data/01streamed&#39; +
                    countryConf[&#39;name&#39;] +
                    &#39;tweet.csv&#39;
                )
                file_path = Path(file_directory_string)

                scrapedTweets.write_tweet_list_file(
                    full_path=file_path
                )

            # add collection to dict
            returnDictCollection[countryConf[&#39;name&#39;]] = scrapedTweets
        print(&#34;End scraping by location&#34;)

    return returnDictCollection</code></pre>
</details>
</dd>
<dt id="helper.scraping.Scraping.doUserSelection"><code class="name flex">
<span>def <span class="ident">doUserSelection</span></span>(<span>self, country, locationUsersCol, eligibleFolCol, readFiles=False, writeFiles=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns final selected users and tweets based on verified
location and language.</p>
<p>Allows imports and exports of results via CSV. Expected path is
'data/03verified' + country + 'users.csv'.
In configuration it is defined how big the sample size should
be and how many users should be selected from which collection.
For users, whose location has been verified, the language criteria
have to be checked. If they are met, the user and fitting tweets
are included in the collection.
For other users both location and language have to be checked.
In the end, a combined user collection and combined tweet collection
is returned, which will be used as input for data preparation.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>country</code></strong> :&ensp;<code>string</code>, default=<code>None, required</code></dt>
<dd>Country name of where the passed users are collected from
(as specified in config)</dd>
<dt><strong><code>locationUsersCol</code></strong> :&ensp;<code>UserCollection</code>, default=<code>None, required</code></dt>
<dd>User collection of location verified users (typically
retrieved via streaming).</dd>
<dt><strong><code>eligibleFolCol</code></strong> :&ensp;<code>UserCollection</code>, default=<code>None, required</code></dt>
<dd>User collection of users whose location is not verified
yet. Typically those are retrieved via doFollowerSelection().</dd>
<dt><strong><code>readFiles</code></strong> :&ensp;<code>boolean</code>, default=<code>False</code></dt>
<dd>If True, CSV files will be read instead of following program
logic.</dd>
<dt><strong><code>writeFiles</code></strong> :&ensp;<code>boolean</code>, default=<code>False</code></dt>
<dd>Can only be True, if readFiles is False. If True, will export
results to CSV files. Allows to read files in the next program
run.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>verifiedUsers</code></strong> :&ensp;<code>UserCollection</code></dt>
<dd>Final verified sample of users as collection.</dd>
<dt><strong><code>verifiedTweetCol</code></strong> :&ensp;<code>TweetCollection</code></dt>
<dd>Final verified sample of tweets as collection (tweets are
written by users in verifiedUsers).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def doUserSelection(
    self,
    country,
    locationUsersCol,
    eligibleFolCol,
    readFiles=False,
    writeFiles=False,
):
    &#34;&#34;&#34;
    Returns final selected users and tweets based on verified
    location and language.

    Allows imports and exports of results via CSV. Expected path is
    &#39;data/03verified&#39; + country + &#39;users.csv&#39;.
    In configuration it is defined how big the sample size should
    be and how many users should be selected from which collection.
    For users, whose location has been verified, the language criteria
    have to be checked. If they are met, the user and fitting tweets
    are included in the collection.
    For other users both location and language have to be checked.
    In the end, a combined user collection and combined tweet collection
    is returned, which will be used as input for data preparation.

    Parameters
    ----------
    country : string, default=None, required
        Country name of where the passed users are collected from
        (as specified in config)
    locationUsersCol : UserCollection, default=None, required
        User collection of location verified users (typically
        retrieved via streaming).
    eligibleFolCol : UserCollection, default=None, required
        User collection of users whose location is not verified
        yet. Typically those are retrieved via doFollowerSelection().
    readFiles : boolean, default=False
        If True, CSV files will be read instead of following program
        logic.
    writeFiles : boolean, default=False
        Can only be True, if readFiles is False. If True, will export
        results to CSV files. Allows to read files in the next program
        run.

    Returns
    -------
    verifiedUsers : UserCollection
        Final verified sample of users as collection.
    verifiedTweetCol : TweetCollection
        Final verified sample of tweets as collection (tweets are
        written by users in verifiedUsers).
    &#34;&#34;&#34;
    if writeFiles is True and readFiles is True:
        raise Exception(
            &#34;readFiles and writeFiles cannot be True at the same time.&#34;
        )

    if readFiles is True:
        print(&#34;\nReading files for User Selection&#34;)
        print(
                &#34;Loading for country: &#34; +
                country
            )

        # base path for saved
        file_directory_string = (
                &#39;data/03verified&#39; +
                country
        )
        # verified and selected users
        file_path_user = Path(
                file_directory_string +
                &#39;users.csv&#39;
        )
        verifiedUsers = UserCollection()
        verifiedUsers.read_user_list_file(
            full_path=file_path_user
        )
        # tweets of verified and selected users
        file_path_tweets = Path(
                file_directory_string +
                &#39;tweets.csv&#39;
        )
        verifiedTweetCol = TweetCollection(
            additionalAttributes=self.config[&#34;twitter&#34;][&#34;add_attributes&#34;]
        )
        verifiedTweetCol.read_tweet_list_file(
            full_path=file_path_tweets
        )

        print(&#34;Files successfully loaded&#34;)

    else:
        # no loading from file
        sampling_location = (
            self.config[&#39;scraping&#39;][&#39;sampling_location_users&#39;]
        )
        sampling_total = self.config[&#39;scraping&#39;][&#39;total_sample_size&#39;]
        sampling_other = sampling_total - sampling_location

        # verify that user&#39;s language and location is correct
        # this call is for already location verified users
        verifiedUsers, verifiedTweetCol = (
            self.verifyUserLocAndLang(
                countryID=country,
                usersCol=locationUsersCol,
                userLimit=sampling_location,
                verifyLocation=False
            )
        )
        # this call is for yet to be location verified users
        verifiedUsers2, verifiedTweetCol2 = (
            self.verifyUserLocAndLang(
                countryID=country,
                usersCol=eligibleFolCol,
                userLimit=sampling_other,
                verifyLocation=self.config[&#39;scraping&#39;][&#39;validateLocation&#39;]
            )
        )

        # join both user and tweet list as our new base of users
        # we add the second results to the first result
        verifiedTweetCol.add_tweet_collection(
            tweetCol=verifiedTweetCol2
        )

        verifiedUsers.userList.extend(verifiedUsers2.userList)

        # only write file if specified
        if writeFiles is True:
            # base path for saved
            file_directory_string = (
                    &#39;data/03verified&#39; +
                    country
            )
            # verified and selected users
            file_path_user = Path(
                    file_directory_string +
                    &#39;users.csv&#39;
            )
            verifiedUsers.write_user_list_file(
                full_path=file_path_user
            )
            # tweets of verified and selected users
            file_path_tweets = Path(
                    file_directory_string +
                    &#39;tweets.csv&#39;
            )
            verifiedTweetCol.write_tweet_list_file(
                full_path=file_path_tweets
            )

    return verifiedUsers, verifiedTweetCol</code></pre>
</details>
</dd>
<dt id="helper.scraping.Scraping.getRandomItemsFromList"><code class="name flex">
<span>def <span class="ident">getRandomItemsFromList</span></span>(<span>self, itemList, numberOfElements=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Based on itemList returns a random sample.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>itemList</code></strong> :&ensp;<code>list</code>, default=<code>None, required</code></dt>
<dd>List of items to draw sample from.</dd>
<dt><strong><code>numberOfElements</code></strong> :&ensp;<code>integer</code>, default=<code>1</code></dt>
<dd>Number of samples to draw from list.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>list</code></strong> :&ensp;<code>list</code></dt>
<dd>Randomly drawn sample.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getRandomItemsFromList(
        self,
        itemList,
        numberOfElements=1,
):
    &#34;&#34;&#34;
    Based on itemList returns a random sample.

    Parameters
    ----------
    itemList : list, default=None, required
        List of items to draw sample from.
    numberOfElements : integer, default=1
        Number of samples to draw from list.

    Returns
    -------
    list : list
        Randomly drawn sample.
    &#34;&#34;&#34;
    return random.sample(itemList, numberOfElements)</code></pre>
</details>
</dd>
<dt id="helper.scraping.Scraping.verifyUserLocAndLang"><code class="name flex">
<span>def <span class="ident">verifyUserLocAndLang</span></span>(<span>self, countryID, usersCol, userLimit=10, verifyLocation=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Return language and location verified users from collection up
to given limit.</p>
<p>A sample should be drawn from the given usersCol. The maximum of
users to select is given by userLimit. Based on countryID the
target language and target language criteria are loaded from
config. <code>checkUserLanguage</code> is called and returns eligible tweets,
that match target language and result if user matches given criteria.
If not, user is skipped. If yes, location is checked (if flag is True).
This is done via <code>checkUserLocation</code>. If location checks out, user
is added to verifiedUsers and its tweets to verifiedTweetCol. Counter
is increased. Process repeated until counter matches limit or all users
processed.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>countryID</code></strong> :&ensp;<code>string</code>, default=<code>None, required</code></dt>
<dd>Country name of where the passed users are collected from
(as specified in config)</dd>
<dt><strong><code>usersCol</code></strong> :&ensp;<code>UserCollection</code>, default=<code>None, required</code></dt>
<dd>User collection from which to draw and verify the sample.</dd>
<dt><strong><code>userLimit</code></strong> :&ensp;<code>integer</code>, default=<code>10</code></dt>
<dd>Full absolute path for file to be loaded via yaml.safe_load().</dd>
<dt><strong><code>verifyLocation</code></strong> :&ensp;<code>boolean</code>, default=<code>True</code></dt>
<dd>Full absolute path for file to be loaded via yaml.safe_load().</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>verifiedUsers</code></strong> :&ensp;<code>UserCollection</code></dt>
<dd>Location and language verified users up to userLimit numbers.</dd>
<dt><strong><code>verifiedTweetCol</code></strong> :&ensp;<code>TweetCollection</code></dt>
<dd>Tweets of verifiedUsers which match the target language.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def verifyUserLocAndLang(
    self,
    countryID,
    usersCol,
    userLimit=10,
    verifyLocation=True,
):
    &#34;&#34;&#34;
    Return language and location verified users from collection up
    to given limit.

    A sample should be drawn from the given usersCol. The maximum of
    users to select is given by userLimit. Based on countryID the
    target language and target language criteria are loaded from
    config. `checkUserLanguage` is called and returns eligible tweets,
    that match target language and result if user matches given criteria.
    If not, user is skipped. If yes, location is checked (if flag is True).
    This is done via `checkUserLocation`. If location checks out, user
    is added to verifiedUsers and its tweets to verifiedTweetCol. Counter
    is increased. Process repeated until counter matches limit or all users
    processed.

    Parameters
    ----------
    countryID : string, default=None, required
        Country name of where the passed users are collected from
        (as specified in config)
    usersCol : UserCollection, default=None, required
        User collection from which to draw and verify the sample.
    userLimit : integer, default=10
        Full absolute path for file to be loaded via yaml.safe_load().
    verifyLocation : boolean, default=True
        Full absolute path for file to be loaded via yaml.safe_load().

    Returns
    -------
    verifiedUsers : UserCollection
        Location and language verified users up to userLimit numbers.
    verifiedTweetCol : TweetCollection
        Tweets of verifiedUsers which match the target language.
    &#34;&#34;&#34;
    countryConf = self.config[&#39;twitter&#39;][&#39;coordinates&#39;][countryID]
    countryName = countryConf[&#39;name&#39;]
    targetLanguage = countryConf[&#39;lang&#39;]
    langThreshold = countryConf[&#39;langThreshold&#39;]
    otherLangThreshold = countryConf[&#39;otherLangThreshold&#39;]

    print(
            &#34;\nStart verifying user location and language until &#34; +
            str(userLimit) +
            &#34; users are verified. Target language is &#34; +
            str(targetLanguage) +
            &#34;. Language Threshold is &#34; +
            str(langThreshold) +
            &#34; and other language threshold is &#34; +
            str(otherLangThreshold)
    )

    verifiedCounter = 0
    verifiedUsers = UserCollection()
    verifiedTweetCol = TweetCollection(
        additionalAttributes=self.config[&#34;twitter&#34;][&#34;add_attributes&#34;]
    )

    for num, user in enumerate(usersCol.userList):
        # retrieve user timeline upto max number of tweets
        max_tweets = self.config[&#34;twitter&#34;][&#34;user_max_tweet_no&#34;]
        result, tweetCol = self.checkUserLanguage(
            user,
            targetLanguage=targetLanguage,
            langThreshold=langThreshold,
            otherLangThreshold=otherLangThreshold,
            limit=max_tweets
        )

        if result is True:
            # language of tweets is okay
            # now check if location is US based
            if verifyLocation is True:
                if user.location == &#39;&#39;:
                    # if user does not give location
                    # result is false
                    locationResult = False
                else:
                    # checks if user&#39;s location is inside country
                    locationResult = self.checkUserLocation(
                        userLocation=user.location,
                        targetLocation=countryName
                    )

            else:
                # if we do not verify
                # it will automatically be true
                locationResult = True

            if locationResult is True:
                # for each user append the tweet list
                # to the verified collection
                verifiedTweetCol.add_tweet_collection(
                    tweetCol=tweetCol
                )
                verifiedUsers.funcAddUser(user)
                verifiedCounter = verifiedCounter + 1
                if (verifiedCounter % (userLimit/10)) == 0:
                    # give progress each 10 percent step
                    print(
                        &#34;Current progress: &#34; +
                        str(verifiedCounter) +
                        &#34; verified users.&#34;
                    )

        if verifiedCounter &gt;= userLimit:
            break

    print(
        &#39;Number of inspected users &#39; +
        str(num + 1) +  # 0 based counting
        &#39; to get &#39; +
        str(verifiedCounter) +
        &#39; verified users.&#39;
    )
    if verifiedCounter &lt; userLimit:
        print(&#34;Limit was not reached.&#34;)

    return verifiedUsers, verifiedTweetCol</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="helper" href="index.html">helper</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="helper.scraping.Scraping" href="#helper.scraping.Scraping">Scraping</a></code></h4>
<ul class="">
<li><code><a title="helper.scraping.Scraping.checkUserLanguage" href="#helper.scraping.Scraping.checkUserLanguage">checkUserLanguage</a></code></li>
<li><code><a title="helper.scraping.Scraping.checkUserLocation" href="#helper.scraping.Scraping.checkUserLocation">checkUserLocation</a></code></li>
<li><code><a title="helper.scraping.Scraping.doFollowerSelection" href="#helper.scraping.Scraping.doFollowerSelection">doFollowerSelection</a></code></li>
<li><code><a title="helper.scraping.Scraping.doScrapingByLocation" href="#helper.scraping.Scraping.doScrapingByLocation">doScrapingByLocation</a></code></li>
<li><code><a title="helper.scraping.Scraping.doUserSelection" href="#helper.scraping.Scraping.doUserSelection">doUserSelection</a></code></li>
<li><code><a title="helper.scraping.Scraping.getRandomItemsFromList" href="#helper.scraping.Scraping.getRandomItemsFromList">getRandomItemsFromList</a></code></li>
<li><code><a title="helper.scraping.Scraping.verifyUserLocAndLang" href="#helper.scraping.Scraping.verifyUserLocAndLang">verifyUserLocAndLang</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>